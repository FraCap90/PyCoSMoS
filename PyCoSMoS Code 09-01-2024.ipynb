{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46c8fba",
   "metadata": {},
   "source": [
    "# Code Description\n",
    "The code consists of the following sub-routines:\n",
    "\n",
    "1) analyzeTS(data, lags, parametric_acs = ('parII', 'wei', 'burrXII'), marg_distr = ('gamma', 'ggamma', 'norm', lognorm', 'burrIII', 'weibull', 'beta'))\n",
    "\n",
    "data is the time series under study;\n",
    "lags is the number of temporal lags to be set by the user;\n",
    "parametric_acs is the parametric autocorrelation structure (acs). This function offers a choice of 3 acs: Pareto II, Weibull and Burr type XII ACS;\n",
    "marg_distr is the marginal distribution chosen by the user suitable for modeling the process under analysis. The user can choose from the following alternatives: Gamma, Generalized Gamma, Normal, Log-normal, Burr type III, Weibull and Beta distributions\n",
    "The output of this function consists of 4 plots: 1) the graph of the observed time series; 2) the empirical density function of nonzero values, i.e, the histogram expressed in terms of probability density; 3) the monthly seasonal components; and 4) the empirical autocorrelation structure.\n",
    "\n",
    "2) Report_ObservedTs(res, lags, method = ('dist', 'acs', 'stat'), show_grid = True)\n",
    "\n",
    "res is the output of the previous step; lags is an input provided in analyzeTS;\n",
    "method offers 3 options: a) 'dist', which provides the Empirical histogram of the observed TS (expressed in terms of probability density) and the parametric distribution function fitted to nonzero values; b) 'acs', which provides the comparison between the empirical and the parametric ACS of the Observed TS; c) 'stat', which provides the summary statistics of the observed TS. The results are provided assuming monthly seasonality.\n",
    "3) MixUnif_TS_Parametric_vs_Empirical_ACS(data, res, lags, parametric_acs, show_grid = True)\n",
    "\n",
    "It requires to provide some inputs from the previous steps. In this step, the observed time series is first transformed to the Mixed-Uniform time series (via mixed-Uniform transformation). Then, a parametric ACS of the transformed rv is fitted to the empirical ACS of the transformed time series (using the ACTF corresponding to the Gaussian to mixed-uniform transformation to estimate the Gaussian ACS. The output provides the comparison between the two ACSs.\n",
    "\n",
    "4) Simulated_TS(data, res, res1, ptsACTF, lags, marg_distr, show_grid=True)\n",
    "\n",
    "It requires to provide some inputs from the previous steps. In this step, the Gaussian time series is generated by using an autoregressive model AR(p) fitted to the Gaussian ACS. Then, the original time series is retrieved by transforming the Gaussian time series. The structure of the output is identical to that of the analyzeTS() function. It allows immediate comparison between the observed and simulated TS.\n",
    "\n",
    "5) Report_SimulatedTs(res, res2, method = ('stat', 'diff_stat')\n",
    "\n",
    "The following function provides the summary statistics of the Simulated TS (when method = 'stat') and the difference between the summary statistics of the Simulated and the Observed TS (when method = 'diff_stat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import similaritymeasures\n",
    "from scipy.special import gamma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma\n",
    "from math import gamma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats \n",
    "import scipy.stats as ss\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.lines as mlines\n",
    "from IPython.display import HTML, display\n",
    "#from IPython.display import display\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.io as pio\n",
    "\n",
    "# Define ACS funtion\n",
    "def acfweibull(lag, scale, shape): return math.exp(-(lag / scale) ** shape) \n",
    "def acfparetoII(lag, scale, shape): return(1 + (shape * lag) / scale)**((-1)/shape)\n",
    "def acfburrXII(lag, scale, shape1, shape2): return((1 + shape2 * (lag / scale)** shape1)** -(1 / shape1 * shape2)) \n",
    "\n",
    "def lmoments(x):\n",
    "    x = np.sort(x)\n",
    "    n = x.shape[0]\n",
    "    nn = np.repeat(np.array([n-1]), [n])\n",
    "    pp = np.linspace(start=0, stop=n-1, num=n)\n",
    "    p1 = pp/nn\n",
    "    p2 = p1*(pp - 1)/(nn - 1)\n",
    "    p3 = p2*(pp - 2)/(nn - 2)\n",
    "  \n",
    "    b0 = sum(x)/n\n",
    "    b1 = sum(p1*x)/n\n",
    "    b2 = sum(p2*x)/n\n",
    "    b3 = sum(p3*x)/n\n",
    "  \n",
    "    l1 = b0\n",
    "    l2 = 2*b1 - b0\n",
    "    l3 = 2*(3*b2 - b0)/(2*b1 - b0) - 3\n",
    "    l4 = 5*(2*(2*b3 - 3*b2) + b0)/(2*b1 - b0) + 6\n",
    "\n",
    "    return l1,l2,l3,l4\n",
    "\n",
    "def ECDF(x):\n",
    "    st = np.sort(x)\n",
    "    aux = stats.rankdata(st, method='min')/(len(x)+1)\n",
    "    out = pd.DataFrame({'p': aux, 'value': st})\n",
    "    return out\n",
    "\n",
    "def rMSE(x, y):\n",
    "      return np.sum((x/y - 1)**2)/len(y) ## ratio MSE\n",
    "def MSE(x, y):\n",
    "      return np.sum((x - y)**2)/len(y) ## MSE\n",
    "def MAE(x, y):\n",
    "      return np.sum(abs(x - y))/len(y) ## MAE \n",
    "    \n",
    "def qggamma(p, shape1, shape2, scale):\n",
    "    q = scale*stats.gamma.ppf(p, scale = 1, a = shape1/shape2)**(1/shape2)\n",
    "    return(q)\n",
    "def pggamma(q, shape1, shape2, scale):\n",
    "    p = stats.gamma.cdf((q/scale)**shape2, scale = 1, a = shape1/shape2)\n",
    "    return(p)\n",
    "def dggamma(x, scale, shape1, shape2):\n",
    "    d = (shape2*(x/scale)**(-1 + shape1))/(np.exp(x/scale)**shape2*scale*gamma(shape1/shape2))\n",
    "    return(d)\n",
    "\n",
    "def qburrXII(p, shape1, shape2, scale):\n",
    "    q = scale*(-((1 - (1 - p)**(-(shape1*shape2)))/shape2))**shape1**(-1) \n",
    "    return(q)\n",
    "def pburrXII(q, shape1, shape2, scale):\n",
    "    p = 1 - (1 + shape2*(q/scale)**shape1)**(-(1/(shape1*shape2))) \n",
    "    return(p)\n",
    "def dburrXII(x, scale, shape1, shape2):\n",
    "    d =  ((x/scale)**(-1 + shape1)*(1 + shape2*(x/scale)**shape1)**(-1 - 1/(shape1*shape2)))/scale\n",
    "    return(d)\n",
    "\n",
    "def qburrIII(p, shape1, shape2, scale):\n",
    "    q = scale*(shape1*(p**(-1/(shape1*shape2)) - 1))**(-shape2) \n",
    "    return(q)\n",
    "def pburrIII(q, shape1, shape2, scale):\n",
    "    p = (1 + 1/(shape1*(q/scale)**shape2**(-1)))**(-(shape1*shape2))\n",
    "    return(p)\n",
    "def dburrIII(x, scale, shape1, shape2):\n",
    "    d =  ((x/scale)**(-1 - shape2**(-1))*(1 + 1/(shape1*(x/scale)**shape2**(-1)))**(-1 - shape1*shape2))/scale\n",
    "    return(d)\n",
    "\n",
    "def pge4(q, shape1, shape2, scale):\n",
    "    p = 1- (((np.exp(q/scale)**shape2) -1)**(shape1/shape2)+1)**(-shape2/shape1)\n",
    "    return(p)\n",
    "def cdf_ge4(x, shape1, shape2, scale):\n",
    "    return (1 - (((np.exp(x/scale)**shape2) -1)**(shape1/shape2)+1)**(-shape2/shape1))\n",
    "def inv_cdf_ge4(p, shape1, shape2, scale, tol=1e-6):\n",
    "    a = 0\n",
    "    b = 10\n",
    "    while (b - a > tol):\n",
    "        mid = (a + b) / 2\n",
    "        if cdf_ge4(np.array(mid), shape1, shape2, scale) < p:\n",
    "            a = mid\n",
    "        else:\n",
    "            b = mid\n",
    "    return (a + b) / 2\n",
    "def qge4(p, shape1, shape2, scale):\n",
    "    return inv_cdf_ge4(p, shape1, shape2, scale)\n",
    "def dge4(x, shape1, shape2, scale):\n",
    "    eps = 1e-6\n",
    "    d = (cdf_ge4(x + eps, shape1, shape2, scale) - cdf_ge4(x - eps, shape1, shape2, scale)) / (2 * eps)\n",
    "    return d\n",
    "\n",
    "def qlogis(p, loc, scale):\n",
    "    q = loc + scale * np.log(p / (1 - p))\n",
    "    return q\n",
    "\n",
    "def analyzeTS(data,lags, parametric_acf = ('parII','wei', 'burrXII'), marg_distr = ('logistic', 'skewnorm','gamma','ggamma','norm', 'lognorm', 'burrIII','burrXII', 'weibull', 'beta', 'weibull3'), n_points = 10): \n",
    "    label= []\n",
    "    for m in range(1,13,1): label.append( 'Month_'+str(m))\n",
    "    data.columns = ['Time', 'Value']\n",
    "    \n",
    "    # Convert Time into Python Time object\n",
    "    Times = pd.to_datetime(data[\"Time\"])\n",
    "    data = data.assign(Time = Times)\n",
    "    \n",
    "    # Add month variable\n",
    "    value = pd.DatetimeIndex(data['Time']).month\n",
    "    data = data.assign(month = value)\n",
    "    \n",
    "    # Assign 0 to NA values\n",
    "    new_value = data['Value'].fillna(data['Value'].mean())\n",
    "    data = data.assign(Value = new_value)\n",
    "    \n",
    "    months = data.month.unique()\n",
    "    stratified_data = {}\n",
    "    p0 = {}\n",
    "    pars_NonZeroValues = {}\n",
    "    u_t = {}\n",
    "    Theoretic = {}\n",
    "    no0values = {}\n",
    "    empAcs_Observed = {}\n",
    "    \n",
    "    def objective_FitDist(par):\n",
    "        edf = ECDF(val) \n",
    "        aux = len(edf) \n",
    "        edf = edf.iloc[range(1, aux, n_points), 0:2]\n",
    "        F = edf['value']\n",
    "        Xi = edf['p'] \n",
    "        if marg_distr == 'gamma':\n",
    "            a, loc, scale = par\n",
    "            Xu = stats.gamma.cdf(edf['value'], a, loc, scale)\n",
    "        elif marg_distr == 'ggamma':\n",
    "            shape1, shape2, scale = par\n",
    "            Xu = pggamma(edf['value'], shape1, shape2, scale)\n",
    "        elif marg_distr == 'ge4':\n",
    "            F = np.array(edf['value'])\n",
    "            temp = np.array(Xi)\n",
    "            shape1, shape2, scale = par\n",
    "            Xu = pge4(edf['value'], shape1, shape2, scale)\n",
    "        elif marg_distr == 'norm':\n",
    "            loc, scale = par\n",
    "            Xu = stats.norm.cdf(edf['value'], loc, scale)\n",
    "        elif marg_distr == 'lognorm':\n",
    "            s, scale = par\n",
    "            Xu = stats.lognorm.cdf(edf['value'], s, scale)\n",
    "        elif marg_distr == 'burrIII':\n",
    "            shape1, shape2, scale = par\n",
    "            Xu = pburrIII(edf['value'], shape1, shape2, scale)\n",
    "        elif marg_distr == 'burrXII':\n",
    "            shape1, shape2, scale = par\n",
    "            Xu = pburrXII(edf['value'], shape1, shape2, scale)\n",
    "        elif marg_distr == 'beta':\n",
    "            a, b = par\n",
    "            Xu = stats.beta.cdf(edf['value'], a, b) \n",
    "        elif marg_distr == 'skewnorm':\n",
    "            a, loc, scale = par\n",
    "            Xu = stats.skewnorm.cdf(edf['value'], a,loc, scale)\n",
    "        elif marg_distr == 'weibull':\n",
    "            c,  scale = par #loc,\n",
    "            Xu = stats.weibull_min.cdf(edf['value'], c,  scale)\n",
    "        elif marg_distr == 'weibull3':\n",
    "            c, loc, scale = par \n",
    "            Xu = stats.weibull_min.cdf(edf['value'], c, loc, scale)\n",
    "        elif marg_distr == 'logistic':\n",
    "            loc, scale = par\n",
    "            Xu = stats.logistic.cdf(edf['value'], loc, scale)\n",
    "\n",
    "        out = MAE(Xi, Xu)\n",
    "        return out\n",
    "\n",
    "    # a) Stratify the observed time series values on a seasonal basis (stratified_data);\n",
    "    # b) Estimate the probability of zero (p0) \n",
    "    # c) Fit a parametric distribution function to nonzero values and store its parameter estimates (pars_NonZeroValues)\n",
    "    # d) Transform the observed time series to mixed-Uniform time series (u_t)\n",
    "    for m in range(1, len(months)+1,1):\n",
    "        data_by_month = pd.DataFrame(data[data['month'] == m])\n",
    "        n = len(data_by_month)\n",
    "        MixedUnif = np.zeros(n)\n",
    "        stratified_data[m] = data_by_month\n",
    "        NonZeroValues = data_by_month[data_by_month['Value'] != 0]\n",
    "        val = NonZeroValues['Value']\n",
    "        df_filter = data_by_month[data_by_month['Value'] > 0]\n",
    "        data_array = np.squeeze(np.asarray(data_by_month.iloc[:, [1]]))\n",
    "        if  marg_distr == 'gamma':\n",
    "            guess_g=[1,1,1]\n",
    "            bnds = ((0.001, None), (0, None), (0.001, None))\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds,method='nelder-mead')\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.gamma.pdf(NonZeroValues['Value'], a=pars[0],loc=pars[1], scale=pars[2])\n",
    "            MixedUnif[data_array > 0] = stats.gamma.cdf(df_filter['Value'], a = pars[0], loc=pars[1], scale=pars[2])\n",
    "            \n",
    "        elif marg_distr == 'ge4':\n",
    "            guess_g=[1,1,1]\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            bnds = ((0.05, None), (0.05, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds,method='nelder-mead')\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = dge4(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) \n",
    "            MixedUnif[data_array > 0] = pge4(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) \n",
    "            \n",
    "        elif marg_distr == 'ggamma':\n",
    "            guess_g=[1,1,1]\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            bnds = ((0.05, None), (0.05, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds,method='nelder-mead')\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = dggamma(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) \n",
    "            MixedUnif[data_array > 0] = pggamma(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) \n",
    "\n",
    "        elif marg_distr == 'weibull':\n",
    "            guess_g=[1,1]\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            bnds = ((0.05, None), (0.05, None))\n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds,method='nelder-mead')\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.weibull_min.pdf(NonZeroValues['Value'], c = pars[0], scale = pars[1])#loc = pars[1],\n",
    "            MixedUnif[data_array > 0] = stats.weibull_min.cdf(df_filter['Value'], c = pars[0], scale = pars[1])#loc = pars[1],\n",
    "        \n",
    "        elif marg_distr == 'weibull3':\n",
    "            guess_g=[2,2,2]\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            bnds = ((0.01, None), (0, None), (0.01, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds,method='nelder-mead')\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.weibull_min.pdf(NonZeroValues['Value'], c = pars[0], loc = pars[1], scale = pars[2])\n",
    "            MixedUnif[data_array > 0] = stats.weibull_min.cdf(df_filter['Value'], c = pars[0], loc = pars[1], scale = pars[2])\n",
    "            \n",
    "        elif marg_distr == 'skewnorm':\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            guess_g=[1,1,1]\n",
    "            bnds = ((0.05, None),(0.05, None),(0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds)\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.skewnorm.pdf(NonZeroValues['Value'], a=pars[0],loc=pars[1], scale = pars[2])\n",
    "            MixedUnif[data_array > 0] = stats.skewnorm.cdf(NonZeroValues['Value'], a=pars[0],loc=pars[1], scale = pars[2]) \n",
    "            \n",
    "        elif marg_distr == 'burrXII':\n",
    "            guess_g=[1,1,1]\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            bnds = ((0.05, None), (0.05, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds)\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = dburrXII(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) #stats.burr12.pdf(NonZeroValues['Value'], c = pars[0], d = pars[1],  loc = 0, scale = pars[3])\n",
    "            MixedUnif[data_array > 0] = pburrXII(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) #stats.burr12.cdf(df_filter['Value'], c = pars[0], d = pars[1] , loc = 0, scale = pars[3])\n",
    "            \n",
    "        elif marg_distr == 'burrIII':\n",
    "            guess_g=[1,1,1]\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            bnds = ((0.05, None), (0.05, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds)\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = dburrIII(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) #stats.burr12.pdf(NonZeroValues['Value'], c = pars[0], d = pars[1],  loc = 0, scale = pars[3])\n",
    "            MixedUnif[data_array > 0] = pburrIII(NonZeroValues['Value'], shape1=pars[0], shape2=pars[1], scale=pars[2]) #stats.burr12.cdf(df_filter['Value'], c = pars[0], d = pars[1] , loc = 0, scale = pars[3])\n",
    "            \n",
    "        elif marg_distr == 'beta':\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            guess_g=[1,1]\n",
    "            bnds = ((0.05, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds)\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.beta.pdf(NonZeroValues['Value'], a = pars[0], b = pars[1])\n",
    "            MixedUnif[data_array > 0] = stats.beta.cdf(df_filter['Value'], a = pars[0], b = pars[1])\n",
    "        \n",
    "        elif marg_distr == 'lognorm':\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            guess_g=[1,1]\n",
    "            bnds = ((0.05, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds)\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.lognorm.pdf(NonZeroValues['Value'], s = pars[0],  scale = pars[1])\n",
    "            MixedUnif[data_array > 0] = stats.lognorm.cdf(df_filter['Value'], s = pars[0],  scale = pars[1])\n",
    "            \n",
    "        elif marg_distr == 'norm':\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            guess_g=[5,5]\n",
    "            bnds = ((None, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds,method='nelder-mead')\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.norm.pdf(NonZeroValues['Value'], loc = pars[0], scale = pars[1])\n",
    "            MixedUnif[data_array > 0] = stats.norm.cdf(df_filter['Value'], loc = pars[0], scale = pars[1])\n",
    "        \n",
    "        elif marg_distr == 'logistic':\n",
    "            NonZeroValues.sort_values(by=['Value'], inplace=True)\n",
    "            guess_g=[1,1]\n",
    "            bnds = ((0.05, None), (0.05, None)) \n",
    "            res = minimize(objective_FitDist,guess_g,bounds=bnds,method='nelder-mead')\n",
    "            pars = res['x'].round(2)\n",
    "            Theoretical = stats.logistic.pdf(NonZeroValues['Value'], loc = pars[0], scale = pars[1])\n",
    "            MixedUnif[data_array > 0] = stats.logistic.cdf(df_filter['Value'], loc = pars[0], scale = pars[1])\n",
    "            \n",
    "        u_t[m] = MixedUnif\n",
    "        Theoretic[m] = Theoretical    \n",
    "        no0values[m] = NonZeroValues\n",
    "        pars_NonZeroValues[m] = pars\n",
    "        count = (data_by_month[data.columns[1]] == 0).sum()/len(data_by_month)\n",
    "        p0[m] = count.round(3)\n",
    "\n",
    "    # Optimization: we find the ACS parameters that minimize the objective function    \n",
    "    # Define objective function for the Nelder-Mead method (Parametric ACS vs Empirical ACS of the Observed TS)\n",
    "    def objective(par):\n",
    "        par_acf = np.zeros((1, lags+1))\n",
    "        if parametric_acf == 'parII':\n",
    "            shape, scale = par\n",
    "            for lag in range(0,lags+1,1):\n",
    "                par_acf[0,lag] = acfparetoII(lag, shape, scale)\n",
    "        elif parametric_acf == 'wei':\n",
    "            shape, scale = par\n",
    "            for lag in range(0,lags+1,1):\n",
    "                par_acf[0,lag] = acfweibull(lag, shape, scale)\n",
    "        elif parametric_acf == 'burrXII':\n",
    "            scale, shape1, shape2 = par\n",
    "            for lag in range(0,lags+1,1):\n",
    "                par_acf[0,lag] = acfburrXII(lag, scale, shape1, shape2)\n",
    "        return similaritymeasures.mae(par_acf,emp_acf)\n",
    "    \n",
    "    mae = np.zeros([len(months),3])\n",
    "    for m in range(0,len(months),1):    \n",
    "        emp_acf = sm.tsa.acf(stratified_data[m+1]['Value'], nlags=lags, fft=False)\n",
    "        empAcs_Observed[m] = emp_acf\n",
    "        if (parametric_acf == 'wei' or parametric_acf == 'parII'):\n",
    "            first_guess = [2, 2]\n",
    "            bnds = ((0.05, None), (0.05, None)) \n",
    "            result = minimize(objective, first_guess,bounds=bnds,  method = 'nelder-mead')\n",
    "            mae[m,0] = result.x[0].round(2)\n",
    "            mae[m,1] = result.x[1].round(2)\n",
    "        elif parametric_acf == 'burrXII':\n",
    "            first_guess = [1, 1, 1]\n",
    "            bnds = ((0.05, None), (0.05, None), (0.05, None)) \n",
    "            result = minimize(objective, first_guess,bounds=bnds,  method = 'nelder-mead')\n",
    "            mae[m,0] = result.x[0].round(2)\n",
    "            mae[m,1] = result.x[1].round(2)\n",
    "            mae[m,2] = result.x[2].round(2)\n",
    "\n",
    "    # Here, we estimate the parametric ACS of the Observed TS using the optimal parameters (par_acf_opt)\n",
    "    par_acf_opt = np.zeros((len(months), lags))\n",
    "    for m in range(0,len(months),1):\n",
    "        for lag in range(0,lags,1):\n",
    "            if parametric_acf == 'parII':\n",
    "                par_acf_opt[m,lag] = acfparetoII(lag, mae[m,0], mae[m,1])\n",
    "            elif parametric_acf == 'wei':\n",
    "                par_acf_opt[m,lag] = acfweibull(lag, mae[m,0], mae[m,1])\n",
    "            elif parametric_acf == 'burrXII':\n",
    "                par_acf_opt[m,lag] = acfburrXII(lag, mae[m,0], mae[m,1], mae[m,2])\n",
    "            emp_acf = sm.tsa.acf(stratified_data[m+1]['Value'], nlags=lags, fft=False)\n",
    "            \n",
    "    return stratified_data, p0, pars_NonZeroValues, par_acf_opt, u_t, Theoretic, no0values, mae, empAcs_Observed\n",
    "\n",
    "\n",
    "def ACF_MixUnif_TS(data, res, lags, parametric_acf = ('parII','wei', 'burrXII')):\n",
    "    u_t = res[4]\n",
    "    label= []\n",
    "    for m in range(1,13,1): label.append( 'Month_'+str(m))\n",
    "    # Rename variables\n",
    "    data.columns = ['Time', 'Value']\n",
    "    \n",
    "    # Convert Time into Python Time object\n",
    "    Times = pd.to_datetime(data[\"Time\"])\n",
    "    data = data.assign(Time = Times)\n",
    "    \n",
    "    # Assign 0 to NA values\n",
    "    new_value = data['Value'].fillna(data['Value'].mean())\n",
    "    data = data.assign(Value = new_value)\n",
    "    \n",
    "    # Add month variable\n",
    "    value = pd.DatetimeIndex(data['Time']).month\n",
    "    data = data.assign(month = value)\n",
    "    \n",
    "    months = data.month.unique()\n",
    "    emp_u_acf = {}\n",
    "            \n",
    "    def objective(par):\n",
    "        par_acf = np.zeros((1, lags))\n",
    "        if parametric_acf == 'parII':\n",
    "            shape, scale = par\n",
    "            for lag in range(0,lags,1):\n",
    "                par_acf[0,lag] = acfparetoII(lag, shape, scale)\n",
    "        elif parametric_acf == 'wei':\n",
    "            shape, scale = par\n",
    "            for lag in range(0,lags,1):\n",
    "                par_acf[0,lag] = acfweibull(lag, shape, scale)\n",
    "        elif parametric_acf == 'burrXII':\n",
    "            shape1, shape2, scale = par\n",
    "            for lag in range(0,lags,1):\n",
    "                par_acf[0,lag] = acfburrXII(lag, scale, shape1, shape2)\n",
    "        return similaritymeasures.mae(par_acf,emp_acf)\n",
    "\n",
    "    mae_u = np.zeros([len(months),3])\n",
    "    for m in range(0,len(months),1):\n",
    "        emp_acf = sm.tsa.acf(u_t[m+1], nlags=lags-1, fft=False)\n",
    "        emp_u_acf[m] = emp_acf\n",
    "        if (parametric_acf == 'wei' or parametric_acf == 'parII'):\n",
    "            first_guess = [2, 2]\n",
    "            bnds = ((0.05, None), (0.05, None)) \n",
    "            result = minimize(objective, first_guess,bounds=bnds,  method = 'nelder-mead')\n",
    "            mae_u[m,0] = result.x[0]\n",
    "            mae_u[m,1] = result.x[1]\n",
    "        elif parametric_acf == 'burrXII':\n",
    "            #mae_u = np.zeros([len(months),3])\n",
    "            first_guess = [1, 1, 1]\n",
    "            bnds = ((0.05, None), (0.05, None), (0.05, None)) \n",
    "            result = minimize(objective, first_guess,bounds=bnds,  method = 'nelder-mead')\n",
    "            mae_u[m,0] = result.x[0]\n",
    "            mae_u[m,1] = result.x[1]\n",
    "            mae_u[m,2] = result.x[2]\n",
    "\n",
    "    # a) We estimate the parametric ACS of the Mixed-Uniform TS using the optimal parameters (par_acf_u_opt)\n",
    "    # b) Plots: Observed Parametric ACS vs Empirical ACS for the Mixed-Uniform TS (for each month)\n",
    "    par_acf_u_opt = np.zeros((12, lags))\n",
    "    par_acf_u_opt_month = np.zeros((1, lags))\n",
    "    \n",
    "    for m in range(1,len(label)+1,1):\n",
    "        for lag in range(0,lags,1):\n",
    "            if parametric_acf == 'parII':\n",
    "                par_acf_u_opt[m-1,lag] = acfparetoII(lag, mae_u[m-1,0], mae_u[m-1,1]) \n",
    "            elif parametric_acf == 'wei':\n",
    "                par_acf_u_opt[m-1,lag] = acfweibull(lag, mae_u[m-1,0], mae_u[m-1,1])\n",
    "            elif parametric_acf == 'burrXII':\n",
    "                par_acf_u_opt[m-1,lag] = acfburrXII(lag, mae_u[m-1,0], mae_u[m-1,1], mae_u[m-1,2])\n",
    "    \n",
    "    return par_acf_u_opt    \n",
    "\n",
    "\n",
    "def SimulatedTS(data, res, res1, ptsACTF, lags, marg_distr = ('gamma','ggamma','norm', 'lognorm', 'beta', 'burrIII', 'weibull', 'weibull3'), show_grid=True):\n",
    "    label= []\n",
    "    for m in range(1,13,1): label.append( 'Month_'+str(m))\n",
    "    p0 = res[1]\n",
    "    par_acf_opt = res[3]\n",
    "    pars_NonZeroValues = res[2]\n",
    "    par_acf_u_opt = res1\n",
    "    \n",
    "    # Rename variables\n",
    "    data.columns = ['Time', 'Value']\n",
    "    # Assign 0 to NA values\n",
    "    new_value = data['Value'].fillna(data['Value'].mean())\n",
    "    data = data.assign(Value = new_value)\n",
    "    \n",
    "    # Convert Time into Python Time object\n",
    "    Times = pd.to_datetime(data[\"Time\"])\n",
    "    data = data.assign(Time = Times)\n",
    "    # Add month variable\n",
    "    value0 = pd.DatetimeIndex(data['Time']).month\n",
    "    data = data.assign(month = value0)\n",
    "    # Add year variable\n",
    "    value1 = pd.DatetimeIndex(data['Time']).year\n",
    "    data = data.assign(year = value1)\n",
    "    \n",
    "    years = data.year.unique()\n",
    "    months = data.month.unique()\n",
    "    n = np.zeros((len(years), len(months)))\n",
    "    rho_z_gaus = {}\n",
    "    \n",
    "    # Take p0, b, c1 and c2 from ptsACTF matrix\n",
    "    p0_grid = np.squeeze(np.asarray(ptsACTF.iloc[:, [0]]))\n",
    "    b = np.squeeze(np.asarray(ptsACTF.iloc[:, [1]]))\n",
    "    c1 = np.squeeze(np.asarray(ptsACTF.iloc[:, [2]]))\n",
    "    c2 = np.squeeze(np.asarray(ptsACTF.iloc[:, [3]]))     \n",
    "    \n",
    "    # Inizialize the Gaussian TS\n",
    "    #np.random.seed(0)                                        \n",
    "    Ts0 = np.random.normal(0, 1, lags-1)\n",
    "    \n",
    "    #Â Store the size of each month in each year (n)\n",
    "    for y in range(0,len(years),1):\n",
    "        for m in range(0,len(months),1):\n",
    "            df2 = pd.DataFrame(data[(data['month'] == m+1) & (data['year'] == years[y])])\n",
    "            n[y,m] = len(df2)\n",
    "    \n",
    "    # Store the size of each month in each year in an array (dim0)\n",
    "    dim0 = []\n",
    "    for l in n: dim0.extend(l)\n",
    "    # Include in dim0 the first steps (# of lags)\n",
    "    dim = np.concatenate([[lags-1],dim0])\n",
    "    \n",
    "    # We construct the Moving Windows to generate the Gaussian TS: we derive the lower and upper bounds of the windows\n",
    "    # Upper bounds (dim2), Lower Bounds (dim1) are defined using cumulative sum of the elements in dim\n",
    "    dim2 = np.array(np.cumsum(dim, axis=None, dtype=None, out=None))\n",
    "    dim1 = dim2-lags+1\n",
    "    \n",
    "    # ind_to_add: Sequence of the Cumulative sum of the numbers of months in Observed TS [0,12,24,36,...]\n",
    "    ind_to_add = np.arange(0, len(years)*len(months), len(months)).tolist()\n",
    "    \n",
    "    # Generate Gaussian TS\n",
    "    for y in range(0,len(years),1):\n",
    "        for m in range(1,len(months)+1,1):\n",
    "            interpolate_p0 = p0[m]\n",
    "            b_interp = interp1d(p0_grid, b)\n",
    "            c1_interp = interp1d(p0_grid, c1)\n",
    "            c2_interp = interp1d(p0_grid, c2)\n",
    "           \n",
    "            df2 = pd.DataFrame(data[(data['month'] == m) & (data['year'] == years[y])])\n",
    "            n = len(df2)\n",
    "            \n",
    "            # ACTF computed from Eq. 11\n",
    "            rho_u = par_acf_u_opt[m-1]\n",
    "            rho_z = ((((1+b_interp(interpolate_p0)*(rho_u)**c1_interp(interpolate_p0))**c2_interp(interpolate_p0))-1)**c2_interp(interpolate_p0))/((((1+b_interp(interpolate_p0))**c2_interp(interpolate_p0))-1)**c2_interp(interpolate_p0))\n",
    "            rho_z_gaus[m] = rho_z\n",
    "            \n",
    "            #Start to generate Gaussian TS using AR(p)\n",
    "            #Create matrix P and its inverse\n",
    "            P = np.zeros((len(rho_z)-1, len(rho_z)-1))\n",
    " \n",
    "            for j in range(len(rho_z)-1):\n",
    "                for i in range(len(rho_z)-1):\n",
    "                    ind = abs(i-j)\n",
    "                    P[j,i] = rho_z[ind] \n",
    "            \n",
    "            Pinv = np.linalg.inv(P)\n",
    "            rho_z2 = np.delete(rho_z, 0)\n",
    "            alpha = Pinv.dot(rho_z2)\n",
    "            mu_eps = 0\n",
    "            sigma_eps = math.sqrt(1-sum(alpha*rho_z2))\n",
    "            alpha_flipped = np.flipud(alpha)\n",
    "            for k in range(n):\n",
    "                eps = np.random.normal(mu_eps, sigma_eps, 1)\n",
    "                to_be_add = sum(Ts0[int(dim1[(m-1)+ind_to_add[y]]+k):int(dim2[(m-1)+ind_to_add[y]]+k)]*alpha_flipped)+ eps\n",
    "                Ts0 = np.concatenate((Ts0, to_be_add))    \n",
    "                \n",
    "    GaussianTS = pd.DataFrame(Ts0[lags-1:], columns = ['Gauss_Ts'])\n",
    "    date = data['Time']\n",
    "    m = pd.DatetimeIndex(data['Time']).month\n",
    "    y = pd.DatetimeIndex(data['Time']).year\n",
    "    \n",
    "    # Add Time, month and year variables\n",
    "    GaussianTS = GaussianTS.assign(Time = date)\n",
    "    GaussianTS = GaussianTS.assign(month = m)\n",
    "    GaussianTS = GaussianTS.assign(year = y)\n",
    "    \n",
    "    # STEP 5: Retrieve original time series using Eq. 13         \n",
    "    Simulated_Ts = []\n",
    "    for y in range(0,len(years),1): # \n",
    "        for m in range(1,len(months)+1,1):\n",
    "            temp = GaussianTS[(GaussianTS['month'] == m) & (GaussianTS['year'] == years[y])] \n",
    "            zm = temp.iloc[:,[0]]\n",
    "            n = len(zm)\n",
    "            # Generate a TS of zeros\n",
    "            Simulated_TS = np.zeros(n)\n",
    "            \n",
    "            # Compute the quantile z_p0_m in Eq. 13\n",
    "            z_p0_m = stats.norm.ppf(p0[m], loc=0, scale=1)\n",
    "            z_filt0 = zm[zm['Gauss_Ts'] > z_p0_m]\n",
    "            z_arr = np.squeeze(np.asarray(zm.iloc[:, [0]]))\n",
    "\n",
    "            if marg_distr == 'gamma':\n",
    "                Simulated_TS[z_arr > z_p0_m] = stats.gamma.ppf((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),a = pars_NonZeroValues[m][0], loc = pars_NonZeroValues[m][1], scale=pars_NonZeroValues[m][2])\n",
    "            elif marg_distr == 'ggamma':\n",
    "                Simulated_TS[z_arr > z_p0_m] = qggamma((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),shape1 = pars_NonZeroValues[m][0],shape2 = pars_NonZeroValues[m][1], scale = pars_NonZeroValues[m][2])\n",
    "            elif marg_distr == 'ge4':\n",
    "                temporary = np.array((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]))\n",
    "                temporary1 = []\n",
    "                for i in range(0,len(temporary),1):\n",
    "                    temporary1.append(qge4(temporary[i],shape1 = pars_NonZeroValues[m][0],shape2 = pars_NonZeroValues[m][1], scale = pars_NonZeroValues[m][2]))\n",
    "                temporary2 = pd.DataFrame(temporary1)\n",
    "                Simulated_TS[z_arr > z_p0_m] = temporary2[0]   \n",
    "                \n",
    "            elif marg_distr == 'norm':\n",
    "                Simulated_TS[z_arr > z_p0_m] = stats.norm.ppf((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),loc = pars_NonZeroValues[m][0],scale = pars_NonZeroValues[m][1])\n",
    "            elif marg_distr == 'lognorm':\n",
    "                Simulated_TS[z_arr > z_p0_m] = stats.lognorm.ppf((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),s = pars_NonZeroValues[m][0], scale = pars_NonZeroValues[m][1])\n",
    "            elif marg_distr == 'weibull3':\n",
    "                Simulated_TS[z_arr > z_p0_m] = stats.weibull_min.ppf((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),c = pars_NonZeroValues[m][0], loc = pars_NonZeroValues[m][1], scale = pars_NonZeroValues[m][2])\n",
    "            elif marg_distr == 'burrIII':\n",
    "                Simulated_TS[z_arr > z_p0_m] = qburrIII((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),shape1 = pars_NonZeroValues[m][0],shape2 = pars_NonZeroValues[m][1], scale = pars_NonZeroValues[m][2])\n",
    "            elif marg_distr == 'beta':\n",
    "                Simulated_TS[z_arr > z_p0_m] = stats.beta.ppf((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),a = pars_NonZeroValues[m][0], b = pars_NonZeroValues[m][1])\n",
    "            elif marg_distr == 'burrXII':\n",
    "                Simulated_TS[z_arr > z_p0_m] = qburrXII((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),shape1 = pars_NonZeroValues[m][0],shape2 = pars_NonZeroValues[m][1], scale = pars_NonZeroValues[m][2])\n",
    "            elif marg_distr == 'skewnorm':\n",
    "                Simulated_TS[z_arr > z_p0_m] = stats.skewnorm.ppf((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),a = pars_NonZeroValues[m][0],loc = pars_NonZeroValues[m][1], scale = pars_NonZeroValues[m][2])\n",
    "            elif marg_distr == 'weibull':\n",
    "                Simulated_TS[z_arr > z_p0_m] = stats.weibull_min.ppf((stats.norm.cdf(z_filt0['Gauss_Ts'], loc=0, scale=1)- p0[m])/(1-p0[m]),c = pars_NonZeroValues[m][0],  scale = pars_NonZeroValues[m][1])\n",
    "      \n",
    "            df_temp = pd.DataFrame(Simulated_TS, columns = ['Value'])\n",
    "            m_sim = np.repeat(months[m-1], len(temp))\n",
    "            y_sim = np.repeat(years[y], len(temp))\n",
    "            \n",
    "            # Add Time, month and year variables\n",
    "            df_temp = df_temp.assign(month = m_sim)\n",
    "            df_temp = df_temp.assign(year = y_sim)\n",
    "            Simulated_Ts.append(df_temp)\n",
    "\n",
    "    SimulatedTS = pd.concat(Simulated_Ts,ignore_index=True)\n",
    "    SimulatedTS = pd.DataFrame(SimulatedTS)\n",
    "    \n",
    "    return SimulatedTS, GaussianTS\n",
    "    \n",
    "def Report_ObservedTS(res, lags, method = ('dist','acf', 'stat'),marg_distr = ('logistic', 'skewnorm','gamma','ggamma','norm', 'lognorm', 'burrIII','burrXII', 'weibull', 'beta'), parametric_acf = ('parII','wei', 'burrXII')): \n",
    "    label= []\n",
    "    for m in range(1,13,1): label.append( 'Month_'+str(m))\n",
    "    stratified_data = res[0]\n",
    "    p0 = res[1]\n",
    "    pars_NonZeroValues = res[2]\n",
    "    par_acf_opt =res[3]\n",
    "    Theoretic = res[5]\n",
    "    no0values = res[6]\n",
    "    acs_par = res[7]\n",
    "    empAcs_Observed = res[8]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Probability density and the Histogram\n",
    "    if method == 'dist':\n",
    "        fig, axs = plt.subplots(3,4, figsize=(15, 8), facecolor='w', edgecolor='k')\n",
    "        fig.subplots_adjust(hspace = .5, wspace=0.25)\n",
    "        fig.text(0.5, 0.04, 'Nonzero values', ha='center', size=15)\n",
    "        fig.text(0.07, 0.5, 'Probability density', va='center', rotation='vertical', size=15)\n",
    "        col_patch = mlines.Line2D([], [], color=(152/255,190/255,88/255), marker='_', \n",
    "                          markersize=3, label='Fitted')\n",
    "        fig.legend(handles = [col_patch],edgecolor='white',handlelength=0.8,bbox_to_anchor=(.9, 0.85), \n",
    "                   borderaxespad=0,fontsize=12, markerfirst=True, markerscale=3) #loc=\"center right\",\n",
    "        \n",
    "        axs = axs.ravel()\n",
    "        for m in range(1,len(label)+1,1):   \n",
    "            axs[m-1].plot(no0values[m]['Value'], Theoretic[m], color=(152/255,190/255,88/255), linewidth=3)\n",
    "            axs[m-1].hist(no0values[m]['Value'], bins=20, density = True, stacked=False, edgecolor='white', linewidth=.5)\n",
    "            axs[m-1].set_title(label[m-1], size=14)\n",
    "            axs[m-1].set_xlabel('',size=12)\n",
    "            axs[m-1].set_ylabel('',size=12)\n",
    "            axs[m-1].tick_params(axis='both', which='major', labelsize=12.5)\n",
    "            axs[m-1].spines['right'].set_visible(False)\n",
    "            axs[m-1].spines['top'].set_visible(False)\n",
    "        fig.savefig('Distr_ObservedTS.png', bbox_inches='tight')\n",
    "\n",
    "    # Plots: Observed Parametric ACS vs Empirical ACS of the Observed TS (for each month)  \n",
    "    elif method == 'acf':\n",
    "        fig, axs = plt.subplots(3,4, figsize=(15, 8), facecolor='w', edgecolor='k')\n",
    "        fig.subplots_adjust(hspace = .5, wspace=0.25)\n",
    "        fig.text(0.5, 0.04, 'Lags', ha='center', size=15)\n",
    "        fig.text(0.08, 0.5, 'Autocorrelation', va='center', rotation='vertical', size=15)\n",
    "        col1_patch = mlines.Line2D([], [],  marker='o', linestyle='None',\n",
    "                          markersize=3, label='Empirical')\n",
    "        col2_patch = mlines.Line2D([], [], color=(168/255, 164/255, 162/255), marker='_', linestyle='None',\n",
    "                          markersize=3, label='Target')\n",
    "        fig.legend(bbox_to_anchor=(.9, 0.85), handles = [col1_patch, col2_patch],markerscale=2,handlelength=0.8,\n",
    "                   loc=\"center right\", borderaxespad=0, edgecolor='white',fontsize=12)\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        for m in range(1,len(label)+1,1):\n",
    "            emp_acf = empAcs_Observed[m-1]\n",
    "            resu=np.concatenate((emp_acf[:10],emp_acf[14::5]))\n",
    "            axs[m-1].plot(range(0,len(par_acf_opt[m-1]),1), par_acf_opt[m-1], color=(168/255, 164/255, 162/255),linewidth=1.5)\n",
    "            axs[m-1].plot(np.where(np.isin(emp_acf, resu))[0],  np.concatenate((emp_acf[:10],emp_acf[14::5])), marker=\"o\", linestyle='')\n",
    "            axs[m-1].set_title(label[m-1], size=14)\n",
    "            axs[m-1].set_ylim([-0.05,1.05])\n",
    "            axs[m-1].set_xlabel('',size=12)\n",
    "            axs[m-1].set_ylabel('',size=12)\n",
    "            axs[m-1].tick_params(axis='both', which='major', labelsize=12.5)\n",
    "            axs[m-1].spines['right'].set_visible(False)\n",
    "            axs[m-1].spines['top'].set_visible(False)\n",
    "    \n",
    "        fig.savefig('Acf_ObservedTS.png', bbox_inches='tight')     \n",
    "        \n",
    "    # Summary statistics\n",
    "    elif method == 'stat':\n",
    "        for m in range(1,len(label)+1,1):\n",
    "            lmom = lmoments(stratified_data[m]['Value'])\n",
    "            lmoment = [round(lmom[0],2), round(lmom[1],2), round(lmom[2],2), round(lmom[3],2)] \n",
    "            summary=pd.DataFrame(stratified_data[m]['Value'].describe(percentiles=[.25, .5, .75, .9, .95,.99]).round(2))\n",
    "            summary = summary.T\n",
    "            l_mom = pd.DataFrame(lmoment).T\n",
    "            l_mom.columns = ['l-mom 1', 'l-mom 2', 'l-mom 3', 'l-mom 4'] #, 'month'\n",
    "            summary.reset_index(drop=True, inplace=True)\n",
    "            l_mom.reset_index(drop=True, inplace=True)\n",
    "            result = pd.concat([summary, l_mom], axis=1)\n",
    "            results[m]=result\n",
    "        resu = pd.concat(results)\n",
    "        resu = resu.drop('count', axis=1)\n",
    "        resu = pd.DataFrame(resu.reset_index(drop=True))\n",
    "        resu.insert(0, \"Month\", ['Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6','Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11',  'Month_12'], True)\n",
    "        pardist_est = np.transpose(pd.DataFrame(pars_NonZeroValues)).round(2)\n",
    "        if  marg_distr == 'gamma':\n",
    "            pardist_est.columns = ['a', 'scale']\n",
    "        elif marg_distr == 'beta':\n",
    "            pardist_est.columns = ['a', 'b']\n",
    "        elif marg_distr == 'norm':\n",
    "            pardist_est.columns = ['loc', 'scale']\n",
    "        elif marg_distr == 'lognorm':\n",
    "            pardist_est.columns = ['s', 'scale']\n",
    "        elif marg_distr == 'skewnorm':\n",
    "            pardist_est.columns = ['a','loc', 'scale']\n",
    "        elif marg_distr == 'logistic':\n",
    "            pardist_est.columns = ['loc', 'scale']\n",
    "        elif marg_distr == 'weibull':\n",
    "            pardist_est.columns = ['c', 'scale']\n",
    "        elif marg_distr == 'weibull3':\n",
    "            pardist_est.columns = ['c', 'loc','scale']\n",
    "        elif marg_distr == 'ggamma' or marg_distr =='ge4' or marg_distr == 'burrIII' or marg_distr =='burrXII':\n",
    "            pardist_est.columns = ['shape1',  'shape2',  'scale']\n",
    "        pardist_est.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        if  parametric_acf == 'parII' or parametric_acf == 'wei':\n",
    "            paracs_est = pd.DataFrame(acs_par).iloc[ :,[0,1]].round(2) \n",
    "            paracs_est.columns = ['b',  'c']\n",
    "        elif parametric_acf == 'burrXII':\n",
    "            paracs_est = pd.DataFrame(acs_par).iloc[ :,[0,1,2]].round(2) \n",
    "            paracs_est.columns = ['shape1',  'shape2',  'scale']\n",
    "\n",
    "        paracs_est.reset_index(drop=True, inplace=True)\n",
    "        summary_stats = pd.concat([resu, pardist_est, paracs_est], axis=1)\n",
    "        \n",
    "        html_df = HTML(summary_stats.to_html(index=False))\n",
    "\n",
    "        return html_df\n",
    "    \n",
    "    \n",
    "def Report_SimulatedTS(res, res2, method = ('acf','stat','diff_stat')): \n",
    "    label= []\n",
    "    for m in range(1,13,1): label.append( 'Month_'+str(m))\n",
    "    styles = [dict(selector=\"caption\",props=[(\"text-align\", \"center\"),(\"font-size\", \"150%\"),(\"color\", 'black')])]\n",
    "    ObservedTS = res[0]\n",
    "    SimulatedTS = res2[0]\n",
    "    par_acf_opt = res[3]  \n",
    "\n",
    "    if method == 'acf':\n",
    "        fig, axs = plt.subplots(3,4, figsize=(15, 8), facecolor='w', edgecolor='k')\n",
    "        fig.subplots_adjust(hspace = .5, wspace=0.25)\n",
    "        fig.text(0.5, 0.04, 'Lags', ha='center', size=15)\n",
    "        fig.text(0.08, 0.5, 'Autocorrelation', va='center', rotation='vertical', size=15)\n",
    "        col1_patch = mlines.Line2D([], [],  marker='o', linestyle='None',\n",
    "                          markersize=3, label='Simulated', color=(181/255, 57/255, 34/255))\n",
    "        col2_patch = mlines.Line2D([], [], marker='_', linestyle='-',markersize=3,\n",
    "                         label='Target', color=(168/255, 164/255, 162/255))\n",
    "        fig.legend(bbox_to_anchor=(.9, 0.85), handles = [col1_patch, col2_patch],markerscale=2,handlelength=0.8,\n",
    "                   loc=\"center right\", borderaxespad=0, edgecolor='white',fontsize=12)\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        for m in range(1,len(label)+1,1):\n",
    "            Simulated_TS_month = SimulatedTS[SimulatedTS['month'] == m]\n",
    "            acf_Ts_simulated_month = sm.tsa.acf(Simulated_TS_month['Value'], nlags=lags, fft=False)  \n",
    "            resu=np.concatenate((par_acf_opt[m-1][:10],par_acf_opt[m-1][14::5]))\n",
    "            resu1=np.concatenate((acf_Ts_simulated_month[:10],acf_Ts_simulated_month[14::5]))\n",
    "            axs[m-1].plot(np.where(np.isin(par_acf_opt[m-1], resu))[0],  np.concatenate((par_acf_opt[m-1][:10],par_acf_opt[m-1][14::5])),  color=(168/255, 164/255, 162/255),linewidth=2)\n",
    "            axs[m-1].plot(np.where(np.isin(acf_Ts_simulated_month, resu1))[0],  np.concatenate((acf_Ts_simulated_month[:10],acf_Ts_simulated_month[14::5])),color=(181/255, 57/255, 34/255), marker=\"o\", linestyle='')\n",
    "            axs[m-1].set_title(label[m-1], size=14)\n",
    "            axs[m-1].set_ylim([-0.05,1.05])\n",
    "            axs[m-1].set_xlabel('',size=12)\n",
    "            axs[m-1].set_ylabel('',size=12)\n",
    "            axs[m-1].tick_params(axis='both', which='major', labelsize=12.5)\n",
    "            axs[m-1].spines['right'].set_visible(False)\n",
    "            axs[m-1].spines['top'].set_visible(False)\n",
    "        fig.savefig('Acf_SimulatedTS.png', bbox_inches='tight')\n",
    "        \n",
    "    elif method == 'stat':\n",
    "        results = {}\n",
    "        for m in range(1,13,1):\n",
    "            stratified_data = pd.DataFrame(SimulatedTS[SimulatedTS['month'] == m])\n",
    "            lmom = lmoments(stratified_data['Value'])\n",
    "            lmoment = [round(lmom[0],2), round(lmom[1],2), round(lmom[2],2), round(lmom[3],2)] \n",
    "            summary = pd.DataFrame(stratified_data['Value'].describe(percentiles=[.25, .5, .75, .9, .95,.99]).round(2))\n",
    "            summary = summary.T\n",
    "            l_mom = pd.DataFrame(lmoment).T\n",
    "            l_mom.columns = ['l-mom 1', 'l-mom 2', 'l-mom 3', 'l-mom 4'] \n",
    "            summary.reset_index(drop=True, inplace=True)\n",
    "            l_mom.reset_index(drop=True, inplace=True)\n",
    "            result = pd.concat([summary, l_mom], axis=1)\n",
    "            results[m]=result\n",
    "        resu_sim = pd.concat(results)\n",
    "        resu_sim = resu_sim.drop('count', axis=1)\n",
    "        resu_sim = pd.DataFrame(resu_sim.reset_index(drop=True))\n",
    "        resu_sim.insert(0, \"Month\", ['Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6','Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11',  'Month_12'], True)\n",
    "\n",
    "        resu_sim.style.set_caption(\"Simulated TS: Summary statistics\").set_table_styles(styles)\n",
    "        display(HTML(resu_sim.to_html(index=False)))\n",
    "            \n",
    "    elif method == 'diff_stat':\n",
    "        results = {}\n",
    "        for m in range(1,13,1):\n",
    "            stratified_data = pd.DataFrame(SimulatedTS[SimulatedTS['month'] == m])\n",
    "            lmom = lmoments(stratified_data['Value'])\n",
    "            lmoment = [round(lmom[0],2), round(lmom[1],2), round(lmom[2],2), round(lmom[3],2)] \n",
    "            summary = pd.DataFrame(stratified_data['Value'].describe(percentiles=[.25, .5, .75, .9, .95,.99]).round(2))\n",
    "            summary = summary.T\n",
    "            l_mom = pd.DataFrame(lmoment).T\n",
    "            l_mom.columns = ['l-mom 1', 'l-mom 2', 'l-mom 3', 'l-mom 4'] \n",
    "            summary.reset_index(drop=True, inplace=True)\n",
    "            l_mom.reset_index(drop=True, inplace=True)\n",
    "            result = pd.concat([summary, l_mom], axis=1)\n",
    "            results[m]=result\n",
    "        resu_sim = pd.concat(results)\n",
    "        resu_sim = resu_sim.drop('count', axis=1)\n",
    "        resu_sim = pd.DataFrame(resu_sim.reset_index(drop=True))\n",
    "        resu_sim.insert(0, \"Month\", ['Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6','Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11',  'Month_12'], True)\n",
    "        \n",
    "        for m in range(1,13,1):\n",
    "            stratified_data = ObservedTS[m]\n",
    "            lmom = lmoments(stratified_data['Value'])\n",
    "            lmoment = [round(lmom[0],2), round(lmom[1],2), round(lmom[2],2), round(lmom[3],2)] \n",
    "            summary=pd.DataFrame(stratified_data['Value'].describe(percentiles=[.25, .5, .75, .9, .95,.99]).round(2))\n",
    "            summary = summary.T\n",
    "            l_mom = pd.DataFrame(lmoment).T\n",
    "            l_mom.columns = ['l-mom 1', 'l-mom 2', 'l-mom 3', 'l-mom 4'] \n",
    "            summary.reset_index(drop=True, inplace=True)\n",
    "            l_mom.reset_index(drop=True, inplace=True)\n",
    "            result = pd.concat([summary, l_mom], axis=1)\n",
    "            results[m]=result\n",
    "        resu_observed = pd.concat(results)\n",
    "        resu_observed = resu_observed.drop('count', axis=1)\n",
    "        resu_observed = pd.DataFrame(resu_observed.reset_index(drop=True))\n",
    "        resu_observed.insert(0, \"Month\", ['Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6','Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11',  'Month_12'], True)\n",
    "\n",
    "        table = resu_observed\n",
    "        colnames = table.columns\n",
    "        for m in range(1, 15,1):\n",
    "            table[colnames[m]] = round(resu_sim[colnames[m]]-resu_observed[colnames[m]],2)\n",
    "        table = pd.DataFrame(data=table)\n",
    "        display(HTML(table.to_html(index=False)))\n",
    "\n",
    "    return \n",
    "\n",
    "def PyCoSMoS_Plots(data, res2): \n",
    "    SimulatedTS = res2[0]\n",
    "    label= []\n",
    "    for m in range(1,13,1): label.append( 'Month_'+str(m))\n",
    "    # Rename variables\n",
    "    data.columns = ['Time', 'Value']\n",
    "    new_value = data['Value'].fillna(data['Value'].mean())\n",
    "    data = data.assign(Value = new_value)\n",
    "    \n",
    "    data['Time'] = pd.to_datetime(data['Time'])\n",
    "    data_temp = data\n",
    "    data_temp['Time'] = data_temp['Time'].astype(str)\n",
    "    data_temp['YM'] = pd.to_datetime(data_temp['Time']).dt.to_period('M')\n",
    "    \n",
    "    data_temp['YM'] = pd.to_datetime(data_temp['Time']).dt.to_period('M')\n",
    "    data_temp['YM'] = data_temp['YM'].astype(str)\n",
    "    data_temp = data_temp.set_index('YM')\n",
    "    data_temp0 = data_temp.drop('Time', axis=1)\n",
    "    \n",
    "    SimulatedTS = pd.DataFrame(SimulatedTS)\n",
    "\n",
    "    # Plot of the observed Time Series\n",
    "    data_temp1 = data\n",
    "    data_temp1 = data_temp1.drop('Value', axis=1)\n",
    "    value = SimulatedTS['Value']\n",
    "    data_temp1 = data_temp1.assign(Values = value)\n",
    "    data_temp1['YM'] = pd.to_datetime(data_temp1['Time']).dt.to_period('M')\n",
    "\n",
    "    data_temp1['YM'] = data_temp1['YM'].astype(str)\n",
    "    data_temp1 = data_temp1.set_index('YM')\n",
    "    data_temp2 = data_temp1.drop('Time', axis=1)    \n",
    "    \n",
    "    fig = plt.figure(figsize = (30, 18), layout=\"constrained\")\n",
    "    spec0 = fig.add_gridspec(ncols=2, nrows=3, width_ratios=[1, 1], height_ratios=[1.6, .7, 2])\n",
    "    spec01 = spec0[0].subgridspec(ncols=1, nrows=2)\n",
    "    spec02 = spec0[2].subgridspec(ncols=3, nrows=1)\n",
    "\n",
    "    ax1 = fig.add_subplot(spec01[0])\n",
    "    ax2 = fig.add_subplot(spec01[1])\n",
    "    ax3 = fig.add_subplot(spec02[0])\n",
    "    ax4 = fig.add_subplot(spec02[1])\n",
    "    ax5 = fig.add_subplot(spec02[2])\n",
    "\n",
    "    def y_fmt(x, pos):\n",
    "        return '{:.0f}'.format(x)\n",
    "\n",
    "    # Aggiunta del primo grafico alla griglia\n",
    "    data_temp0.plot(label = 'Observed', linewidth=0.5, ax=ax1) #\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.set_ylabel(\"Precipitation (mm)\", fontsize = 16) \n",
    "    ax1.set_xlabel(\"Time\", fontsize = 16)\n",
    "    ax1.tick_params(axis='both', labelsize=15)\n",
    "    ax1.legend().remove()\n",
    "    ax1.legend(['Observed'], loc='upper right', fontsize=14, handlelength=0, frameon=True,\n",
    "                       edgecolor='lightgray', facecolor=(227/255, 222/255, 220/255), shadow=True)\n",
    "\n",
    "    # Aggiunta del primo grafico alla griglia\n",
    "    data_temp2.plot(label = 'Simulated', color= (182/255, 90/255, 73/255),linewidth=0.5 ,  ax=ax2)#\n",
    "    ax2.spines['right'].set_visible(False) \n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.set_ylabel(\"Precipitation (mm)\", fontsize = 16)\n",
    "    ax2.set_xlabel(\"Time\", fontsize = 16)\n",
    "    ax2.tick_params(axis='both', labelsize=15)\n",
    "    ax2.yaxis.set_major_formatter(ticker.FuncFormatter(y_fmt))\n",
    "    ax2.legend().remove()\n",
    "    ax2.legend(['Simulated'], loc='upper right', fontsize=14, handlelength=0, frameon=True,\n",
    "                       edgecolor='lightgray', facecolor= (227/255, 222/255, 220/255), shadow=True)\n",
    "\n",
    "    #Plot 3\n",
    "    y = pd.DataFrame(data[data['Value'] != 0])\n",
    "    yy = pd.DataFrame(SimulatedTS[SimulatedTS['Value'] != 0])\n",
    "\n",
    "    # Creazione del plot\n",
    "    sns.kdeplot(y['Value'], alpha=0.4,shade=True, ax=ax3,fill=True, common_norm=False, linewidths=2)\n",
    "    sns.kdeplot(yy['Value'], color=(182/255, 90/255, 73/255), alpha=0.4,shade=True, ax=ax3)\n",
    "    \n",
    "    # Impostazione del titolo e delle etichette degli assi\n",
    "    ax3.set_ylabel('Density', fontsize = 16)\n",
    "    ax3.set_xlabel('Nonzero values', fontsize = 16)\n",
    "    ax3.tick_params(axis='both', labelsize=15)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "\n",
    "    #Seasonal components\n",
    "    df_temp = data\n",
    "    df_temp['Time'] = pd.to_datetime(df_temp['Time'], errors='coerce')\n",
    "    df_temp = (df_temp.groupby([pd.Grouper(key='Time', freq='MS')])['Value']\n",
    "           .sum().reset_index())\n",
    "\n",
    "    value = pd.DatetimeIndex(df_temp['Time']).month\n",
    "    df_temp = df_temp.assign(month = value)\n",
    "    df_temp0 = df_temp.groupby(['month']).mean()\n",
    "\n",
    "    df_temp1 = pd.DataFrame(SimulatedTS)\n",
    "    df_temp1 = df_temp1.groupby(['year','month'])[\"Value\"].sum()\n",
    "    df_temp2 = pd.DataFrame(df_temp1.groupby(['month']).mean())\n",
    "    labels=[]\n",
    "    for m in range(1,13,1): labels.append(str(m))\n",
    "    df_temp2 = df_temp2.assign(Month = labels)\n",
    "    ax4.plot(labels, df_temp0['Value'], linewidth=2)\n",
    "    ax4.plot(labels, df_temp2['Value'],linewidth=2, color=(182/255, 90/255, 73/255))\n",
    "    ax4.set_xlabel('Months',size=16)\n",
    "    ax4.set_ylabel('Precipitation (mm)',size=16) \n",
    "    ax4.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax4.spines['right'].set_visible(False)\n",
    "    ax4.spines['top'].set_visible(False)\n",
    "\n",
    "    #Autocorrelation function\n",
    "    acf_ObservedTs = sm.tsa.acf(data['Value'], nlags=lags, fft=False)\n",
    "    acf_SimulatedTs = sm.tsa.acf(SimulatedTS['Value'], nlags=lags, fft=False)\n",
    "    resu=np.concatenate((acf_ObservedTs[:10],acf_ObservedTs[14::5]))\n",
    "    resu1=np.concatenate((acf_SimulatedTs[:10],acf_SimulatedTs[14::5]))\n",
    "\n",
    "    ax5.plot(np.where(np.isin(acf_ObservedTs, resu))[0],  np.concatenate((acf_ObservedTs[:10],acf_ObservedTs[14::5])) , 'o')\n",
    "    ax5.plot(np.where(np.isin(acf_SimulatedTs, resu1))[0], np.concatenate((acf_SimulatedTs[:10],acf_SimulatedTs[14::5])) , color=(182/255, 90/255, 73/255), marker='o', linestyle='')\n",
    "    ax5.set_xlabel('Lags',size=16)\n",
    "    ax5.set_ylabel('ACF',size=16)\n",
    "    ax5.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax5.spines['right'].set_visible(False)\n",
    "    ax5.spines['top'].set_visible(False)\n",
    "    ax5.set_ylim([-0.05,1.05])\n",
    "    fig.savefig('PyCoSMoS_Plots.png', bbox_inches='tight')\n",
    "\n",
    "    # Visualizzazione del plot\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "ptsACTF = read_csv('/Users/francesco/Desktop/Paper Arno/Jupyter Notebook/interpolationPntsACTF.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
